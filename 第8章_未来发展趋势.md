# 第 8 章 未来发展趋势

在第 7 章中，我们讨论了在线多模态理解（OMU）的典型应用场景和面临的主要挑战。本章将展望 OMU 领域的未来发展趋势，探讨如何通过技术创新突破现有局限，推动该领域向更高性能、更强鲁棒性、更广应用的方向发展。

## 8.1 预测式未来建模的深化

### 8.1.1 从特征预测到结构化预测

当前的预测式未来建模（Predictive Future Modeling, PFM）主要预测未来的**特征表示**（如 PreFM [1]），未来可向**结构化预测**方向发展。

**多层次预测**：

**（1）特征级预测**（当前阶段）：
- 预测 f̂_{t+k}（特征向量）
- 优势：简单、稳定
- 局限：缺乏可解释性

**（2）语义级预测**（下一阶段）：
- 预测未来的事件类别概率分布 ŷ_{t+k}
- 预测未来的模态可见性 m̂_{t+k}
- 优势：可解释性强，可用于早期预警

**（3）时空结构预测**（长期目标）：
- 预测未来帧的场景布局（物体位置、运动轨迹）
- 预测音频的频谱包络
- 优势：提供更丰富的未来信息

**示例**（自动驾驶场景）：
```
当前（t=0s）：检测到车辆 A 在 50m 前
预测（t+1s）：车辆 A 将移动至 35m 前，速度 15m/s
预测（t+2s）：车辆 A 将变道，概率 0.7
决策：提前 0.5s 准备刹车
```

**技术路线**：
- **概率预测**：输出分布而非点估计，量化不确定性
- **多假设预测**：预测多个可能的未来（如车辆可能直行或变道）
- **分层预测**：短期预测（1-3 帧）精确，长期预测（5-10 帧）粗略

**预期收益**：
- 性能提升：从当前的 +3-4% **相对提升**（绝对 F1 点数）提升至 +5-8%（**在 AVE/LLP 等中等规模数据集上、严格在线评测协议下的估算范围**）
- 可解释性增强：预测结果可直接用于人类理解和验证
- 应用拓展：支持主动规划和提前响应

### 8.1.2 因果预测与反事实推理

**因果预测**：不仅预测"将会发生什么"，还预测"为什么会发生"。

**技术框架**：

**（1）因果图学习**：
- 学习变量间的因果关系图（如"鸣笛声 → 车辆靠近"）
- 使用结构因果模型（SCM）[2]

**（2）反事实推理**（Counterfactual Reasoning）：
- "如果没有鸣笛声，车辆位置会怎样？"
- 帮助模型理解模态间的因果关系，而非仅相关性

**（3）干预预测**（Intervention Prediction）：
- 预测采取某个动作后的未来状态
- 应用：机器人决策、主动监控

**潜在影响**：
- 提升域泛化能力（因果关系比相关性更稳定）
- 增强可解释性（能够回答"为什么"）
- 支持主动决策（预测干预效果）

### 8.1.3 PFM 的不确定性建模与多假设解码

**动机**：

在线场景中，错误的"过早"预测代价高（如误报警、错误决策）。应显式输出预测的置信度与不确定性，支持风险感知的决策。

**方法框架**：

**（1）分布式回归**：

以高斯混合模型对未来特征或语义分布建模；损失采用负对数似然（NLL）：

```
L_NLL = -Σ_k log(Σ_m π_m · N(f^(k) | μ_m^(k), Σ_m^(k)))
```

其中 m 为混合成分数（通常 3-5），π_m 为混合权重，μ_m、Σ_m 为均值和协方差。

**（2）多假设预测（Multi-Hypothesis Prediction, MHP）**：

一次产生 M 条未来轨迹 {ŷ^(k,m)}_{m=1}^M，用**最小化匹配损失**训练：

```
L_MHP = min_m CE(ŷ^(k,m), y^(k))
```

推理时，输出 M 个假设及其置信度，决策系统可选择保守策略（如取概率最高或等待更多信息）。

**（3）不确定性分解与门控**：

- **认知不确定性（Epistemic）**：模型参数的不确定性，可通过蒙特卡洛 Dropout 估计
- **随机不确定性（Aleatoric）**：数据本身的噪声，通过建模输出分布估计

当不确定性超过阈值时，**延后告警或切换到保守策略**（如提高判定阈值或触发人审兜底）。

**落地建议**：

报告 **Epistemic-Aleatoric 分解**（使用蒙特卡洛 Dropout 或核密度估计 KDE），并在 Acc@Δt 曲线上叠加**置信筛选**后的性能（如"仅报告置信度 >0.8 的预测"）。

**预期效果**：
- 在高置信预测上，F1 可提升 **+2-4%**
- 覆盖率：约 70-80%（20-30% 低置信样本延后或人审）

## 8.2 大模型与流式推理的结合

### 8.2.1 大模型在线化挑战与机遇

大语言模型（LLM）和多模态大模型（如 GPT-4V、Gemini）展现了强大的理解和推理能力，但其在线化面临巨大挑战 [3, 4]。

**挑战量化**：

| 模型规模 | 参数量 | 单次前向延迟 (p50/p95) | KV 缓存（2048 ctx） | 适用性 |
|---------|--------|---------------------|-------------------|--------|
| 小模型 | 10^7-10^8 | 10-50ms / 15-70ms | 0.5-2GB | ✓ 可在线 |
| 中模型 | 10^8-10^9 | 50-200ms / 80-300ms | 2-8GB | △ 宽松在线 |
| 大模型 | 10^9-10^10 | 200-1000ms / 350-1500ms | 8-32GB | ✗ 难以在线 |
| 超大模型 | >10^11 | >5000ms / >8000ms | >100GB | ✗ 仅离线 |

*注：延迟为 batch=1、FP16（或 INT8）、V100/A100 GPU；KV 缓存为**每层每头统一精度假设**；含 K/V + 路由缓存（MoE）时可能增加 10-30%*

**在线化路径**：

**（1）渐进式蒸馏**：
```
GPT-4V（1000B+） 
  ↓ 蒸馏
中等模型（10B）→ 延迟 200-500ms（宽松在线）
  ↓ 进一步蒸馏
轻量模型（100M-1B）→ 延迟 30-100ms（严格在线）
```

**性能预期**（基于相关工作的趋势）：
- 100M 参数模型：可达 GPT-4V 的 **60-70%** 性能，延迟 30-50ms
- 1B 参数模型：可达 GPT-4V 的 **75-85%** 性能，延迟 80-150ms

**（2）稀疏激活与专家混合（MoE）** [5]：
- 模型总参数 10B，但每次前向仅激活 1B（10% 激活率）
- 延迟降低至 **1/10**（理论），实际约 **1/5-1/3**（受路由开销影响）
- **算子层开销**：路由网络（<1ms）+ all-to-all 通信（5-20ms，取决于拓扑）+ 负载均衡（可能触发重路由）
- **拓扑影响**：多卡互联方式显著影响实际加速（NVLink 约 600GB/s vs PCIe 4.0 约 64GB/s，差异 **9×**）
- 挑战：路由网络本身需要计算，专家负载不均衡

**（3）投机解码与并行预测**：
- 使用小模型快速生成多个候选
- 大模型并行验证候选（避免逐 token 生成）
- 加速比：2-3×（对生成任务）

### 8.2.2 流式大模型架构设计

**关键技术方向**：

**（1）高效注意力机制**：
- **线性注意力**：复杂度从 O(n²) 降至 O(n)
- **分块注意力**：将长序列切分为固定大小块
- **状态空间模型（SSM）**：如 Mamba [6]，O(n) 复杂度，支持流式

**多模态对齐提醒**：**在多模态场景下，线性注意力/SSM 需显式时间对齐与模态标记 token**，否则跨模态信息泄漏（如未来音频影响当前视觉）会导致指标虚高，破坏因果性。

**（2）长上下文窗口**：
- 当前：2k-8k token 上下文
- 目标：32k-128k token（支持分钟-小时级视频）
- 技术：RoPE 外推、ALiBi、分层注意力

**（3）分块因果注意力时延预算**：

块大小 B、滑移步长 H（H ≤ B），单块计算延迟 T_B，跨块汇聚 T_bridge，则：

```
T_p50 ≈ T_B + ((B-H)/B)·T_bridge
吞吐量 ≈ H / T_B
```

据此选择 B, H 达成"延迟 ≤ 预算、吞吐 ≥ 目标"。

**（4）多模态对齐**：
- 统一的 token 化策略（视觉、音频、文本统一为 token 序列）
  - 视觉：ViT patch 16×16，224² → 196 tokens/帧
  - 音频：25ms hop Mel-patch → 40 tokens/秒
  - Token 化速率：30fps 视频 → 5,880 视觉 + 40 音频 ≈ **5.9k tokens/秒**
- 跨模态位置编码（编码模态类型和时间戳）
- 模态适配器（将不同模态投影到统一语义空间）

**长上下文换算**（脚注参见本章末）：
- 32k 上下文 ≈ **5.4 秒**视频（按 5.9k tokens/秒）
- 64k 上下文 ≈ **10.8 秒**视频
- **10 分钟视频需 350k+ tokens**，应使用**分块/检索/层次记忆**而非线性扩窗

**预期发展**（2-3 年内）：
- 1B 参数的流式多模态大模型，延迟 <100ms，性能接近当前 10B 离线模型
- 支持 64k-128k token 上下文（10-20 秒视频）+ 检索增强（支持更长视频）
- 支持 5+ 模态（视觉、音频、文本、深度、IMU 等）

---

## 表 8.1 流式多模态大模型系统指标要求

| 能力维度 | 指标 | 建议口径 | 评价要点 |
|---------|------|---------|---------|
| **延迟** | p50/p95/p99 (ms) | batch=1、224²、FP16/INT8、V100/Orin | 报告包含解码/门控 |
| **上下文** | 有效上下文（tokens / 秒） | 显式给出"每帧 tokens→每秒 tokens" | 含跨模态对齐开销 |
| **内存** | KV 缓存/激活峰值 (GB) | 长序列（32k/64k）两点 | 含多专家路由缓存 |
| **吞吐** | FPS / RTF | 长视频稳定运行 10+ 分钟 | 预热后曲线 |
| **鲁棒** | Missing/Delay/Jitter 曲线 | 见第 6 章协议 | 报告相对下降 |
| **能耗** | TOPS/W 或 W/FPS | NVML/功率计，60s 均值 | 附测量方法脚注 |

*注：以上 6 类指标形成**标准卡**随模型权重一并开放*

---

## 8.3 自监督学习的前沿应用

### 8.3.1 时序自监督信号

**新型自监督任务**：

**（1）因果顺序预测**：
- 打乱视频片段，预测正确顺序
- 学习时序因果依赖（"鸣笛声 → 车辆出现"）

**（2）未来帧生成与对比**：
- 生成未来帧的多种可能
- 对比学习区分真实未来与生成未来

**（3）跨模态未来对齐**：
- 预测："给定当前视觉，预测未来音频"
- 反向："给定当前音频，预测未来视觉"
- 双向预测的一致性作为监督信号

**（4）慢特征分析（Slow Feature Analysis）**：
- 学习随时间缓慢变化的高层表示
- 适合建模场景级语义（如"在厨房做饭"持续数分钟）

### 8.3.2 大规模预训练

**数据规模扩展**：

| 当前 | 目标（2-3年内） | 数据来源 |
|------|---------------|---------|
| AVE: 4k 视频 | 100k-1M 视频 | YouTube、TikTok、监控数据 |
| LLP: 11k 视频 | 500k-10M 视频 | 开源数据集汇总 |
| Kinetics: 650k 片段 | 10M-100M 片段 | 多源数据聚合 |

**预训练范式演进**：

**（1）多任务预训练**：
- 同时学习事件分类、模态对齐、未来预测等多个任务
- 任务间知识共享，提升泛化能力

**（2）持续预训练**：
- 定期在新数据上增量预训练
- 避免灾难性遗忘（使用经验回放、正则化等）

**（3）跨域预训练**：
- 在多个域（YouTube、监控、电影、游戏）上预训练
- 学习域不变的多模态表示

**预期收益**：
- 性能提升：+5-10%（相比当前小规模预训练）
- 零样本能力：在未见过的类别上也能泛化
- 少样本学习：仅需 10-50 个样本即可适应新任务

## 8.4 边缘智能与硬件-软件协同

### 8.4.1 专用硬件加速器

**神经网络加速器趋势**：

**（1）NPU/TPU 演进**：
- 当前：Google TPU v4（275 TFLOPS）、华为 Ascend 910（256 TFLOPS）
- 趋势：针对稀疏计算、动态形状优化
- 预期：3-5× 能效比提升（TOPS/W）

**（2）时序专用加速**：
- 针对 RNN/LSTM 的专用单元（降低递归计算延迟）
- 因果注意力加速器（硬件实现因果掩码和 KV 缓存）
- 预期延迟：5-10× 加速（相比通用 GPU）

**（3）模态融合加速器**：
- 跨模态注意力的硬件实现
- 音视频同步单元（硬件级时间戳对齐）

**（4）片上系统（SoC）集成**：
- 集成 CPU + GPU + NPU + ISP（图像信号处理器）+ DSP（音频）
- 减少数据搬移，降低延迟和功耗
- 典型产品：NVIDIA Orin（254 TOPS），高通 8 Gen 3（45 TOPS）

### 8.4.2 算法-硬件协同设计

**联合优化方向**：

**（1）混合精度硬件支持**：
- 不同层使用不同精度（INT4/INT8/FP16 混合）
- 硬件支持动态精度切换（零开销）
- 预期：在保持 FP16 性能下，功耗降低 **40-60%**

**混合精度能效上界估计**：

设层集合 L 按敏感度分为 S（需 FP16）与 Q（可 INT8/INT4），单位能耗比 ρ = FP16:INT8:INT4 = 1:0.45:0.25。则单位工作负载能耗上界：

```
E_mix ≤ Σ_{l∈S} c_l · 1 + Σ_{l∈Q} c_l · ρ_q
```

给出**能耗节省率** = 1 - E_mix / Σ_l c_l。

**实践建议**：优先将 FFN 层量化（占 FLOPs 的 60-70%），保持注意力层 FP16（占 30-40%，但对精度敏感）。

**（2）稀疏计算加速**：
- 硬件跳过零值或小值计算
- 动态剪枝支持（运行时自适应稀疏度）
- 预期：实际加速比接近理论稀疏度（当前仅 40-60% 理论值）

**（3）流式计算架构**：
- 硬件流水线设计（特征提取、时序建模、融合并行）
- 片上缓存优化（减少显存访问）
- **片上 SRAM 命中率**对能效影响 >2×；建议报告 **DRAM 访问次数 / 算术运算次数**（访存-计算比）
- 预期：延迟降低 **30-50%**，能效比提升 **2-3×**

### 8.4.3 端-边-云协同

**三层架构**：

```
[端侧]（移动设备、IoT）
  ↓ 轻量模型（<100M 参数）
  ↓ 延迟 <50ms，功耗 <5W
  ↓ 简单任务直接响应
  ↓
[边缘侧]（基站、边缘服务器）
  ↓ 中等模型（100M-1B 参数）
  ↓ 延迟 <200ms，功耗 <100W
  ↓ 复杂任务 + 多路汇聚
  ↓
[云侧]（数据中心）
  ↓ 大模型（>10B 参数）
  ↓ 延迟 <2s，功耗不受限
  ↓ 高难度任务 + 模型更新
```

**动态调度策略**：
- **置信度路由**：高置信度（>0.9）端侧处理，低置信度上传边缘/云端
- **延迟预算路由**：严格实时任务（<50ms）仅端侧，宽松任务可云端
- **带宽感知**：网络拥塞时优先端侧处理，降低上传

**预期效果**：
- 端侧处理比例：70-80%（大部分简单任务）
- 平均端到端延迟：<100ms（相比纯云端的 500-2000ms）
- 带宽占用：降低 **70-80%**

## 8.5 多模态大模型的在线化

### 8.5.1 统一多模态表示

**当前问题**：不同模态使用不同编码器（ResNet、VGGish、BERT），表示空间不统一。

**统一表示方向**：

**（1）Token 化统一**：
- 将所有模态转换为 token 序列
- 视觉：Patch embedding（如 ViT [7]）
  - **Stride 设置**：16×16 patch，输入 224² → 196 tokens/帧
  - 30fps 视频 → 5,880 tokens/秒（视觉）
- 音频：Spectrogram patch 或波形段
  - **Stride 设置**：25ms hop，80-bin Mel → 40 tokens/秒（音频）
- 文本：BPE/WordPiece tokenization（约 1-2 tokens/词）
- 统一输入格式：`[CLS] <视觉 tokens> <音频 tokens> <文本 tokens> [SEP]`
- **总 token 化速率**：30fps 视频 ≈ 5.9k tokens/秒（视觉+音频）

**（2）跨模态预训练目标**：
- 掩码多模态建模（Masked Multimodal Modeling, M3）
- 跨模态对比学习（CLIP 扩展到视频-音频-文本）
- 跨模态因果语言建模

**（3）模态适配器（Adapter）**：
- 冻结大模型主干，仅训练轻量适配器（<1% 参数）
- 快速适配新模态（如深度、热成像）
- 延迟增加：<5%

### 8.5.2 流式 Transformer 优化

**长序列优化**：

**（1）FlashAttention 及后续** [8]：
- 优化注意力计算的内存访问模式
- 加速：2-4×，显存降低：10-20×
- 支持更长上下文（从 2k → 32k）

**（2）状态空间模型（SSM）的兴起**：
- Mamba、S4 等模型：O(n) 复杂度，天然支持流式
- 长程依赖能力强（百万 token 上下文）
- 当前局限：在多模态任务上的探索较少

**（3）分块因果注意力**：
- 将序列分为多个块，块内全局注意力，块间因果注意力
- 兼顾长程依赖和因果性
- 复杂度：O(n·B)（B 为块大小，通常 64-256）

**预期性能**（2-3 年内，基于趋势外推）：
- 1B 参数流式 Transformer：延迟 <50ms，F1 约 75-78%（接近当前离线 SOTA）
- 支持 64k token 上下文（约 30 分钟视频）
- 显存占用：<8GB（边缘 GPU 可运行）

## 8.6 标准化与开源生态

### 8.6.1 评测基准标准化

**当前问题**：
- 不同论文使用不同评测协议（Δt 设定、硬件环境、阈值选择）
- 难以公平对比不同方法
- 缺少官方排行榜（Leaderboard）

**标准化需求**：

**（1）统一评测协议**：
- 标准化 Δt 设定：{0, 50, 100, 200, 500} ms
- 标准化硬件基准：V100、A100、Jetson Xavier
- 标准化鲁棒性测试：Missing-Rate@{10%, 30%}、Audio-Delay@{50, 100, 200} ms
- **必报指标**：F1/mAP、延迟 (p50/p95/p99)、Acc@Δt 曲线、**FAH（每小时误报数）**、**能耗（W/FPS）**

**（2）开源评测工具**：
- 提供标准化评测脚本（Python 包）
- 自动生成评测报告（包含所有必需指标）
- 支持多种硬件后端（PyTorch、TensorFlow、ONNX）

**（3）在线评测排行榜**：
- 类似 ImageNet、COCO 的官方排行榜
- 提交要求：代码、模型、完整环境信息
- 多维度排名：准确率、延迟、显存、综合得分

### 8.6.3 在线排行榜与提交流程规范

**任务分轨**：
- AVEL（音视频事件定位）
- AVEP（音视频事件解析）
- AVVP（弱监督视频解析）
- Streaming-VideoQA（流式视频问答）
- Open-Vocab-OMU（开放词汇多模态理解）

**强制提交物**：

提交 ZIP 包必须包含：
1. **metrics.json**：
   - F1/mAP、Acc@Δt（多个 Δt）
   - Latency (p50/p95/p99/max)
   - FAH（误报率）、Memory（显存峰值）
   
2. **env.yaml**：
   - 框架版本（PyTorch/TensorFlow）
   - CUDA/cuDNN 版本
   - Python 版本与关键依赖
   
3. **hardware.txt**：
   - GPU 型号、数量、显存
   - 驱动版本、功耗设置
   - CPU、内存配置
   
4. **reproduce.sh**：
   - 完整评测脚本
   - 环境设置命令
   - 数据预处理流程

**反作弊机制**：
- 在线评测沙箱随机插入"**未来遮挡样本**"（随机遮挡 t+1 到 t+k 帧）
- 若预测受未来影响（对比遮挡前后的预测差异 >阈值），则判**无效提交**
- 因果性验证：计算图拓扑检查 + 梯度流分析

**多维榜单**：
1. **Accuracy 榜**：F1/mAP 排序（传统指标）
2. **Latency 榜**：在 F1 >阈值（如 70%）条件下，按延迟排序
3. **Pareto 榜**：在准确率-延迟空间，按 Pareto 前沿面积占优排序
4. **综合榜**：权重可调的综合分（α·F1 + β/Latency + γ/Memory），支持用户自定义权重复现实际场景

### 8.6.2 开源数据集与模型库

**数据集建设**：

**（1）大规模在线挑战数据集**（迫切需求）：
- 规模：100k-1M 视频
- 包含在线特有挑战：模态异步（±50-500ms）、缺失（10-50%）、抖动（±10-50ms）
- 长视频：包含 1 分钟-1 小时视频（测试长期记忆）
- 细粒度标注：帧级 + 模态可见性连续值

**（2）域多样性数据集**：
- 覆盖多个域：监控、自动驾驶、医疗、工业
- 支持域泛化和域适应研究

**模型库建设**：

**（1）标准化模型实现**：
- 提供 PreFM、StreamAV 等模型的官方实现
- 统一接口（huggingface transformers 风格）
- 预训练权重公开

**（2）模型动物园**：
- 不同规模变体（Tiny/Small/Base/Large）
- 不同优化版本（FP32/FP16/INT8）
- 不同硬件适配（V100/Jetson/移动）

## 8.7 跨学科融合

### 8.7.1 认知科学启发

**人类在线感知机制**：
- **预测编码理论**（Predictive Coding）：大脑持续预测感官输入，最小化预测误差 [9]
- **注意力机制**：人类选择性关注重要信息，忽略无关信息
- **多模态整合**：视觉、听觉在丘脑和皮层融合

**借鉴方向**：
- 实现生物学合理的预测机制（层次化预测、误差最小化）
- 模拟人类注意力的选择性和动态性
- 研究多模态融合的神经科学基础

### 8.7.2 因果推理与可解释性

**因果发现**：
- 从观测数据中学习因果图（而非仅相关性）
- 使用结构因果模型（SCM）、do-calculus [2]

**可解释性增强**：
- 可视化模型的因果推理路径
- 反事实解释："如果没有音频，模型会预测什么？"
- 支持人类审核和信任建立

### 8.7.3 神经形态计算

**神经形态芯片**（如 Intel Loihi、IBM TrueNorth）：
- 事件驱动（Event-Driven）计算，仅在输入变化时计算
- 超低功耗（<1W），适合边缘永久在线
- 天然支持时序和流式处理

**OMU 适配**：
- 将音视频事件转换为脉冲序列（Spike Trains）
- 使用脉冲神经网络（SNN）进行推理
- 预期功耗：**1/10-1/100**（相比传统 GPU）

**条件限定**：上述节能比在**事件稀疏场景**（如监控中 80% 时间为背景）或**低刷新率**（<10fps）时更明显；密集场景或高刷新率下优势减弱。同时需注意**训练-推理域差异**（SNN 训练工具链不成熟，可能影响性能）。

---

## 效度威胁声明（Threats to Validity）

本章预测性数字多基于工程外推与公开报告的趋势分析，其可迁移性受以下因素影响：

**（1）硬件代差**：GPU/NPU 架构每 1-2 年演进（如 V100 → A100 → H100），实际延迟和能效可能偏离估算 **±30-50%**。

**（2）Token 化策略**：不同 patch size、hop length 导致 tokens/秒差异 **2-5×**，影响长上下文换算。

**（3）任务与数据域偏移**：AVE/LLP 等中等规模数据集的结论可能不适用于长视频、开放词汇或多域场景。

**（4）算法创新不确定性**：未来可能出现突破性新架构（如 SSM 的后续演进），颠覆当前预测。

**免责与建议**：**除特别标注外，数值为趋势外推与工程经验的区间估计，并非跨论文可直接横比**。我们在附录公开环境、口径与脚本，仍建议读者在目标硬件与数据域中复核关键结论。

---

## 8.8 本章小结

本章展望了 OMU 领域的未来发展趋势，主要方向包括：

**（1）预测式建模深化**：
- 从特征预测 → 结构化预测（语义级、时空结构级）
- 引入因果预测与反事实推理
- 预期性能提升：从当前 +3-4% 增至 +5-8%

**（2）大模型在线化**：
- 渐进式蒸馏：1000B+ → 1B 参数，延迟 <100ms
- 稀疏激活（MoE）：激活率 10%，延迟降低 1/5-1/3
- 流式 Transformer 优化：线性注意力、SSM（Mamba）、长上下文（32k-128k token）
- 预期：1B 模型性能接近当前 10B 离线模型，延迟 <100ms

**（3）自监督学习前沿**：
- 新型时序自监督任务（因果顺序、未来对齐、慢特征）
- 大规模预训练（100k-10M 视频，+5-10% 性能）
- 跨域预训练（多域知识共享，增强泛化）

**（4）边缘智能**：
- 专用加速器（NPU/TPU）：5-10× 延迟加速，3-5× 能效提升
- 算法-硬件协同：混合精度、稀疏计算、流式架构
- 端-边-云协同：端侧处理 70-80% 任务，平均延迟 <100ms

**（5）标准化与生态**：
- 统一评测协议（标准 Δt、硬件基准、鲁棒性测试）
- 开源评测工具与排行榜
- 大规模数据集（100k-1M 视频，包含在线挑战）
- 模型库与预训练权重

**（6）跨学科融合**：
- 认知科学启发（预测编码、选择性注意力）
- 因果推理（因果发现、反事实解释）
- 神经形态计算（事件驱动、超低功耗 1/10-1/100）

**时间表预期**（基于当前趋势）：

| 时间点 | 预期里程碑 |
|--------|----------|
| **2025** | 1B 流式模型延迟 <100ms，性能 75-77%；标准评测协议发布 |
| **2026** | 100k 规模在线挑战数据集；离线-在线差距 <2% |
| **2027** | 专用加速器商用化；端侧 1B 模型实时运行（<50ms） |
| **2028+** | 多模态大模型全面在线化；认知启发架构成为主流 |

在下一章（第 9 章）中，我们将总结全文，回顾 OMU 的研究意义、本文的主要工作以及未来的挑战与机遇。

---

## 脚注：长上下文换算示例

**视频 token ↔ 文本 token 的换算**：

假设视频采用 ViT patch（16×16），输入 224² → 196 视觉 tokens/帧；音频以 25ms hop 的 Mel-patch 序列化 → 40 tokens/秒。

**换算公式**：
- 30fps 视频 → 5,880 视觉 tokens/秒 + 40 音频 tokens/秒 ≈ **5.9k tokens/秒**
- **32k 上下文** ≈ 32,000 / 5,900 ≈ **5.4 秒**视频
- **64k 上下文** ≈ 64,000 / 5,900 ≈ **10.8 秒**视频
- **10 分钟视频** ≈ 600 × 5,900 ≈ **354k tokens**

**关键结论**：如需覆盖 10 分钟或更长视频，应使用**分块处理 / 检索增强 / 层次记忆**而非线性扩窗，否则 KV 缓存和计算复杂度将不可接受。

**注意事项**：
- 不同 patch size（如 14×14 vs 16×16）会改变 tokens/帧
- 不同采样率（如 15fps vs 30fps）会改变 tokens/秒
- 上述换算为示例，实际应用需根据具体配置调整

---

## 本章参考文献

[1] Wang, Y., Li, J., Chen, X., Zhang, L., and Liu, H. PreFM: Predictive future modeling for online audio-visual event parsing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.

[2] Pearl, J. and Mackenzie, D. The Book of Why: The New Science of Cause and Effect. Basic Books, 2018.

[3] Brown, T.B., Mann, B., Ryder, N., et al. Language models are few-shot learners. In Proceedings of Advances in Neural Information Processing Systems (NeurIPS), pages 1877-1901, 2020.

[4] OpenAI. GPT-4 technical report. arXiv preprint arXiv:2303.08774, 2023.

[5] Fedus, W., Zoph, B., and Shazeer, N. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. Journal of Machine Learning Research, 23: 1-39, 2022.

[6] Gu, A. and Dao, T. Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint arXiv:2312.00752, 2023.

[7] Dosovitskiy, A., Beyer, L., Kolesnikov, A., et al. An image is worth 16x16 words: Transformers for image recognition at scale. In Proceedings of the International Conference on Learning Representations (ICLR), 2021.

[8] Dao, T., Fu, D.Y., Ermon, S., Rudra, A., and Ré, C. FlashAttention: Fast and memory-efficient exact attention with IO-awareness. In Proceedings of Advances in Neural Information Processing Systems (NeurIPS), pages 16344-16359, 2022.

[9] Friston, K. The free-energy principle: A unified brain theory? Nature Reviews Neuroscience, 11(2): 127-138, 2010.

